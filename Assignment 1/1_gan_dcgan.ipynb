{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RostislavKorst/GANs-MIPT-2022-Masters/blob/main/Assignment%201/1_gan_dcgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "OUCkVdFc___N"
      },
      "source": [
        "# Generative Models\n",
        "***\n",
        "\n",
        "**MIPT, Autumn 2022, MSc course**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ML_snL71___T"
      },
      "source": [
        "## Assignment 1\n",
        "\n",
        "***\n",
        "\n",
        "\n",
        "*Authored by Arip Asadulaev & Manh Lab*\n",
        "\n",
        "*Adapted by Alexander Panfilov*\n",
        "\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JXCL_bw8___U"
      },
      "source": [
        "The assignment is split into two parts: at first, you will implement classical GAN for the MNIST dataset, and after, you will enhance your results with DCGAN and the CIFAR dataset. \n",
        "\n",
        "Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "EUILjtbd___V"
      },
      "source": [
        "## 1. GAN\n",
        "*Source: <a href=\"https://arxiv.org/pdf/1406.2661.pdf\" target=\"_blank\">Goodfellow, Ian J., et al. \"Generative Adversarial Networks.\" arXiv preprint arXiv:1406.2661 (2014)</a>.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Glhi9UoTJR0T",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In 2014, Ian Goodfellow and his colleagues at the University of Montreal published a stunning paper introducing the world to GANs, or generative adversarial networks. The models play two distinct (literally, adversarial) roles. Given some real data set $\\mathcal{X}$, $G$ is the generator, trying to create fake data that looks just like the genuine data, while $D$ is the discriminator, getting data from either the real set or $G$ and labeling the difference.\n",
        "\n",
        "Goodfellow’s metaphor (and a fine one it is) was that $G$ was like a team of forgers trying to match real paintings with their output, while $D$ was the team of detectives trying to tell the difference. (Except in this case, the forgers $G$ never get to see the original data — only the judgments of $D$. They’re like blind forgers.)\n",
        "\n",
        "<img src=\"https://production-media.paperswithcode.com/methods/gan.jpeg\" style=\"display=block; margin:auto\"/>\n",
        "<p style=\"text-align: center\">\n",
        "    <b>Picture taken from the <a href=\"https://paperswithcode.com/method/gan\" target=\"_blank\">paperswithcode</a> website. There you can find a whole bunch of papers on GANs with implementation.</b>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "v2s_R0-J___W"
      },
      "source": [
        "In this part, we are going to implement classical GAN. You can find a rough plan on how to do it below; however, it is not mandatory to stick with it precisely but one might expect some questions related to the listed steps. Feel free to adapt provided code!\n",
        "\n",
        "- Define the parameters\n",
        "- Load the data (with transforms and normalization)\n",
        "- Denormalize for visual inspection of samples\n",
        "- Define the Discriminator network, the Generator network\n",
        "- Study the activation function: Leaky ReLU\n",
        "- Explain the output activation function: Tanh, Sigmoid\n",
        "- Look at some sample outputs\n",
        "- Define losses, optimizers and helper functions for training\n",
        "     - For Discriminator\n",
        "     - For Generator\n",
        "- Train the model\n",
        "- Save intermediate generated images to file\n",
        "- Look at some outputs\n",
        "- Save the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "t5m0Z5Sn___X"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bLWJJFYI___Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10, MNIST\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLj6X3bVn3eT",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Define parameters & data loading "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uI1speTm___a"
      },
      "outputs": [],
      "source": [
        "hidden_size = 256\n",
        "batch_size = 100\n",
        "LR = 0.0002\n",
        "num_epochs = 300\n",
        "sample_dir = \"./images\"\n",
        "latent_size = 64  # input random input vector latent\n",
        "image_size = 784  # 28*28 flatten\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)\n",
        "## Define the dataset\n",
        "mnist_dataset = MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=Compose([ToTensor(), Normalize(mean=(0.5,), std=(0.5,))]),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tv3tRhsc___b"
      },
      "outputs": [],
      "source": [
        "img, label = mnist_dataset[0]\n",
        "print(\"Label: \", label)\n",
        "plt.hist(img[:, 5:15, 5:15].flatten(), bins=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mDTAJ9hN___b"
      },
      "outputs": [],
      "source": [
        "# denormalization image from range (-1)-1 to range 0-1 to display it\n",
        "def denorm(x):\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FdQspwIB___c"
      },
      "outputs": [],
      "source": [
        "# show image sample with matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NFmgyzny___c"
      },
      "outputs": [],
      "source": [
        "# define the dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "KPGRU37y___d"
      },
      "source": [
        "### GAN implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "oCPhhAgp___d"
      },
      "source": [
        "GAN consists of two deep networks, a generator ($G$) and a discriminator ($D$). The generator creates images before learning it. Since the discriminator is a binary classification model, we can use the binary cross-entropy loss function to quantify how well it can distinguish between real and generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Eb6z7nry___d"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_size, image_size, hidden_size):\n",
        "        super(Generator, self).__init__()\n",
        "        ## set a linear layer with input size is latent_size and output size is hidden_size\n",
        "\n",
        "        # set a linear layer with input size is hidden_size and output size is hidden_size\n",
        "\n",
        "        # set a linear layer with input size is hidden_size and output size is image_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # forward x -> linear1 -> relu -> linear2 -> relu -> linear3 -> tanh\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_size, hidden_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        ## set a linear layer with input size is image_size and output size is hidden_size\n",
        "\n",
        "        # set a linear layer with input size is hidden_size and output size is hidden_size\n",
        "\n",
        "        # set a linear layer with input size is hidden_size and output size is 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        # forward x -> linear1 -> relu -> linear2 -> relu -> linear3 -> sigmoid\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "dhViiJdk___e"
      },
      "source": [
        "### Create the Generator and Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n102NpQJ___e"
      },
      "outputs": [],
      "source": [
        "# create new Generator model\n",
        "\n",
        "# G = Generator...\n",
        "\n",
        "# create new Discriminator model\n",
        "\n",
        "# D = Discriminator..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rESTDDE5___f"
      },
      "outputs": [],
      "source": [
        "# show the output of model\n",
        "y = G(torch.randn(2, latent_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cDqDOGc-___f"
      },
      "outputs": [],
      "source": [
        "# define the criterion is nn.BCELoss()\n",
        "\n",
        "## Define the optimizer for generator and discrimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "UreJsJKb___g"
      },
      "source": [
        "Discriminator Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Rs4ZPjcP___g"
      },
      "outputs": [],
      "source": [
        "def reset_grad():\n",
        "    ## reset gradient for optimizer of generator and discrimator\n",
        "\n",
        "def train_discriminator(D_model, G_model, images):\n",
        "  \n",
        "    # Create the labels which are later used as input for the BCE loss\n",
        "    real_labels = torch.ones(batch_size, 1).to(device)\n",
        "    fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "        \n",
        "    \n",
        "    outputs = D_model(images)\n",
        "    # Loss for real images\n",
        "    \n",
        "    real_score = outputs\n",
        "\n",
        "    # Loss for fake images\n",
        "    z = torch.randn(batch_size, latent_size).to(device)\n",
        "    fake_images = G_model(z)\n",
        "    outputs = D_model(fake_images)\n",
        "\n",
        "    fake_score = outputs\n",
        "\n",
        "    # Sum losses\n",
        "\n",
        "    # Reset gradients\n",
        "\n",
        "    # Compute gradients\n",
        "\n",
        "    # Adjust the parameters using backprop\n",
        "    \n",
        "    return d_loss, real_score, fake_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "GPF-F7k2___h"
      },
      "source": [
        "Generator Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Yx02VmkA___h"
      },
      "outputs": [],
      "source": [
        "def train_generator(G_model):\n",
        "    # Generate fake images and calculate loss\n",
        "    # z = torch.randn(batch_size, latent_size).to(device)\n",
        "    z = torch.Tensor(np.random.normal(0, 1, (batch_size, latent_size))).to(device)\n",
        "    fake_images = G_model(z)\n",
        "    labels = torch.ones(batch_size, 1).to(device)\n",
        "    # calculate the generator loss\n",
        "\n",
        "    # Reset gradients\n",
        "\n",
        "    # Backprop and optimize\n",
        "\n",
        "    return g_loss, fake_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FJHs15NF___i"
      },
      "source": [
        "### Start the training proccess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dlUgHAi6___i"
      },
      "outputs": [],
      "source": [
        "# function to save the sample output of generator\n",
        "def save_fake_images_mnist(G_model, index):\n",
        "    # sample_vectors = torch.randn(batch_size, latent_size).to(device)\n",
        "    sample_vectors = torch.Tensor(np.random.normal(0, 1, (batch_size, latent_size))).to(\n",
        "        device\n",
        "    )\n",
        "    fake_images = G_model(sample_vectors)\n",
        "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
        "    fake_fname = \"fake_images-{0:0=4d}.png\".format(index)\n",
        "    print(\"Saving\", fake_fname)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aCsHM9uS___j"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "total_step = len(data_loader)\n",
        "d_losses, g_losses, real_scores, fake_scores = [], [], [], []\n",
        "G.to(device)\n",
        "D.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        # Load a batch & transform to vectors\n",
        "        images = images.reshape(batch_size, -1).to(device)\n",
        "\n",
        "        # Train the discriminator\n",
        "\n",
        "        # Train the generator\n",
        "\n",
        "        # Inspect the losses\n",
        "        if (i + 1) % 200 == 0:\n",
        "            d_losses.append(d_loss.item())\n",
        "            g_losses.append(g_loss.item())\n",
        "            real_scores.append(real_score.mean().item())\n",
        "            fake_scores.append(fake_score.mean().item())\n",
        "            print(\n",
        "                \"Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}\".format(\n",
        "                    epoch,\n",
        "                    num_epochs,\n",
        "                    i + 1,\n",
        "                    total_step,\n",
        "                    d_loss.item(),\n",
        "                    g_loss.item(),\n",
        "                    real_score.mean().item(),\n",
        "                    fake_score.mean().item(),\n",
        "                )\n",
        "            )\n",
        "    # Sample and save images\n",
        "    save_fake_images_mnist(epoch + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Dlm4M7ja___j"
      },
      "outputs": [],
      "source": [
        "# show output after epochs training\n",
        "Image(os.path.join(sample_dir, \"fake_images-0225.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LuLUwaaY___k"
      },
      "outputs": [],
      "source": [
        "# show the discrimator loss and generator loss\n",
        "plt.plot(d_losses, \"-\")\n",
        "plt.plot(g_losses, \"-\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend([\"Discriminator\", \"Generator\"])\n",
        "plt.title(\"Losses\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KXe1OMMA___l"
      },
      "outputs": [],
      "source": [
        "# plot the accuracy of discrimator\n",
        "plt.plot(real_scores, \"-\")\n",
        "plt.plot(fake_scores, \"-\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"score\")\n",
        "plt.legend([\"Real Score\", \"Fake score\"])\n",
        "plt.title(\"Scores\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VxjGRy71___l"
      },
      "source": [
        "## 2. DCGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "R2SBUbSM___m"
      },
      "source": [
        "*Source: <a href=\"https://arxiv.org/pdf/1511.06434v2.pdf\" target=\"_blank\">Radford, Alec, Luke Metz, and Soumith Chintala. \"Unsupervised representation learning with deep convolutional generative adversarial networks.\" arXiv preprint arXiv:1511.06434 (2015)</a>.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "AOaZuDsv___m"
      },
      "source": [
        "The goal of this part is to enhance your results achieved in the part one with DCGAN. Feel free to reuse your code, improve architecture or training scheme, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jJWbnASW___m"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    batch_size = 128\n",
        "    num_epochs = 300\n",
        "    workers = 4\n",
        "    seed = 2021\n",
        "    image_size = 64\n",
        "    download = True\n",
        "    dataroot = \"data\"\n",
        "    nc = 3  ## number of chanels\n",
        "    ngf = 64  # Size of feature maps in generator\n",
        "    nz = 100  # latent random input vector\n",
        "    ndf = 64  # Size of feature maps in discriminator\n",
        "    lr = 0.0002\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    sample_dir = \"./images/\"\n",
        "\n",
        "\n",
        "if not os.path.exists(CFG.sample_dir):\n",
        "    os.makedirs(CFG.sample_dir)\n",
        "\n",
        "cifar_dataset = CIFAR10(\n",
        "    root=CFG.dataroot,\n",
        "    download=CFG.download,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize([CFG.image_size, CFG.image_size]),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ]\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1zQ13kF6___n"
      },
      "outputs": [],
      "source": [
        "img, label = cifar_dataset[0]\n",
        "print(\"Label: \", label)\n",
        "plt.hist(img[:, 5:15, 5:15].flatten(), bins=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bQek-_xx___o"
      },
      "outputs": [],
      "source": [
        "# unnormalization image from range (-1)-1 to range 0-1 to display it\n",
        "def denorm(img):\n",
        "    # write your code\n",
        "\n",
        "# show  image sample with matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QCgngJq5___o"
      },
      "outputs": [],
      "source": [
        "# create the dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8Eeg3xE8___o"
      },
      "source": [
        "### DCGAN implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tlvyHI7Q___p"
      },
      "outputs": [],
      "source": [
        "class DCGenerator(nn.Module):\n",
        "    def __init__(self, nc, nz, ngf):\n",
        "        # ConvTranspose2d - BatchNorm - Relu -ConvTranspose2d - BatchNorm - Relu -ConvTranspose2d - BatchNorm - Relu\n",
        "        # ConvTranspose2d - BatchNorm - Relu - ConvTranspose2d - Tanh\n",
        "        super(Generator, self).__init__()\n",
        "        ##\n",
        "\n",
        "    def forward(self, x):\n",
        "        ##\n",
        "        return F.tanh(x)\n",
        "\n",
        "\n",
        "class DCDiscriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf):\n",
        "        # conv2d - leaky - conv2d - batchnorm - leaky - conv2d - batchnorm - leaky - conv - batchnorm - leaky - conv2d\n",
        "        super(Discriminator, self).__init__()\n",
        "        ##\n",
        "\n",
        "    def forward(self, x):\n",
        "        ##\n",
        "        return F.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sPVR9Rh1___p"
      },
      "outputs": [],
      "source": [
        "# create new Generator model\n",
        "\n",
        "# DCG = DCGenerator...\n",
        "\n",
        "# create new Discriminator model\n",
        "\n",
        "# DCD = DCDiscriminator..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Gq2e2ccb___p"
      },
      "outputs": [],
      "source": [
        "# show the output of model\n",
        "y = DCG(torch.randn(2, CFG.nz))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "13uPUnSB___q"
      },
      "outputs": [],
      "source": [
        "# define the criterion is nn.BCELoss()\n",
        "criterion = nn.BCELoss()\n",
        "## Define the optimizer for generator and discrimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IkrRHEa3___q"
      },
      "outputs": [],
      "source": [
        "# feel free to reuse your training functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "j7ONDPUq___r"
      },
      "source": [
        "### Start the training proccess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ByYpMvdf___r"
      },
      "outputs": [],
      "source": [
        "def save_fake_images_cifar(DCG_model, index):\n",
        "    sample_vectors = torch.randn(CFG.batch_size, CFG.nz, 1, 1).to(CFG.device)\n",
        "    fake_images = DCG_model(sample_vectors)\n",
        "    fake_images = fake_images.reshape(fake_images.size(0), 3, 64, 64)\n",
        "    fake_fname = \"fake_images-{0:0=4d}.png\".format(index)\n",
        "    print(\"Saving\", fake_fname)\n",
        "    save_image(\n",
        "        denorm(fake_images), os.path.join(CFG.sample_dir, fake_fname), nrow=10\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jVBi-pBJ___r"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "device = CFG.device\n",
        "num_epochs = CFG.num_epochs\n",
        "batch_size = CFG.batch_size\n",
        "\n",
        "total_step = len(data_loader)\n",
        "d_losses, g_losses, real_scores, fake_scores = [], [], [], []\n",
        "DCG.to(device)\n",
        "DCD.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        # Load a batch & transform to vectors\n",
        "        images = images.reshape(batch_size, -1).to(device)\n",
        "\n",
        "        # Train the discriminator\n",
        "\n",
        "        # Train the generator\n",
        "\n",
        "        # Inspect the losses\n",
        "        if (i + 1) % 200 == 0:\n",
        "            d_losses.append(d_loss.item())\n",
        "            g_losses.append(g_loss.item())\n",
        "            real_scores.append(real_score.mean().item())\n",
        "            fake_scores.append(fake_score.mean().item())\n",
        "            print(\n",
        "                \"Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}\".format(\n",
        "                    epoch,\n",
        "                    num_epochs,\n",
        "                    i + 1,\n",
        "                    total_step,\n",
        "                    d_loss.item(),\n",
        "                    g_loss.item(),\n",
        "                    real_score.mean().item(),\n",
        "                    fake_score.mean().item(),\n",
        "                )\n",
        "            )\n",
        "    # Sample and save images\n",
        "    save_fake_images_cifar(epoch + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "V-23l5zp___s"
      },
      "outputs": [],
      "source": [
        "# show your results!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}